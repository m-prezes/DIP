{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from master_thesis.core.utils.reproducibility import seed_everything\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "\n",
    "DATASETS_DIR = f\"../../../../data/datasets/base_experiments/europe_vs_usa\"\n",
    "\n",
    "POSITIVE_LABEL_POSITIVE_CONFOUNDING_RATIO_LIST = [0.5, 0.95]\n",
    "DATASETS_NAME = \"europe_vs_usa\"\n",
    "POSITIVE_LABEL_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"{DATASETS_DIR}/test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_confounding_test_df(\n",
    "    df, positive_confounding_size=95, negative_confounding_size=5, random_state=42\n",
    "):\n",
    "    positive_confounding_df = df[df[\"confounding\"] == 1].sample(\n",
    "        positive_confounding_size, random_state=random_state\n",
    "    )\n",
    "    negative_confounding_df = df[df[\"confounding\"] == 0].sample(\n",
    "        negative_confounding_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        pd.concat([positive_confounding_df, negative_confounding_df])\n",
    "        .sample(frac=1, random_state=random_state)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_balanced_test_df(\n",
    "    df,\n",
    "    positive_label_positive_confounding_size=50,\n",
    "    positive_label_negative_confounding_size=50,\n",
    "    random_state=42,\n",
    "):\n",
    "    positive_label_df = df[df[\"label\"] == 1]\n",
    "    negative_label_df = df[df[\"label\"] == 0]\n",
    "\n",
    "    positive_label_part = prepare_confounding_test_df(\n",
    "        positive_label_df,\n",
    "        positive_confounding_size=positive_label_positive_confounding_size,\n",
    "        negative_confounding_size=positive_label_negative_confounding_size,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    negative_label_part = prepare_confounding_test_df(\n",
    "        negative_label_df,\n",
    "        positive_confounding_size=positive_label_negative_confounding_size,\n",
    "        negative_confounding_size=positive_label_positive_confounding_size,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        pd.concat([positive_label_part, negative_label_part])\n",
    "        .sample(frac=1, random_state=random_state)\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (\n",
    "    positive_label_positive_confounding_ratio\n",
    ") in POSITIVE_LABEL_POSITIVE_CONFOUNDING_RATIO_LIST:\n",
    "    positive_label_positive_confounding_size = int(\n",
    "        POSITIVE_LABEL_SIZE * positive_label_positive_confounding_ratio\n",
    "    )\n",
    "    positive_label_negative_confounding_size = (\n",
    "        POSITIVE_LABEL_SIZE - positive_label_positive_confounding_size\n",
    "    )\n",
    "\n",
    "    balanced_test_df = prepare_balanced_test_df(\n",
    "        test_df,\n",
    "        positive_label_positive_confounding_size=positive_label_positive_confounding_size,\n",
    "        positive_label_negative_confounding_size=positive_label_negative_confounding_size,\n",
    "    )\n",
    "    balanced_test_df.to_csv(\n",
    "        f\"{DATASETS_DIR}/test/test_{positive_label_positive_confounding_size}_{positive_label_negative_confounding_size}.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Dataset: europe_vs_usa, 50/50\n",
      "Test dataset shape: (200, 5)\n",
      "Test dataset label distribution:\n",
      "label\n",
      "1    100\n",
      "0    100\n",
      "Name: count, dtype: int64\n",
      "Test dataset confounding distribution by label:\n",
      "label  confounding\n",
      "0      0              50\n",
      "       1              50\n",
      "1      0              50\n",
      "       1              50\n",
      "Name: count, dtype: int64\n",
      "============================\n",
      "Dataset: europe_vs_usa, 95/5\n",
      "Test dataset shape: (200, 5)\n",
      "Test dataset label distribution:\n",
      "label\n",
      "1    100\n",
      "0    100\n",
      "Name: count, dtype: int64\n",
      "Test dataset confounding distribution by label:\n",
      "label  confounding\n",
      "0      0              95\n",
      "       1               5\n",
      "1      1              95\n",
      "       0               5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for (\n",
    "    positive_label_positive_confounding_ratio\n",
    ") in POSITIVE_LABEL_POSITIVE_CONFOUNDING_RATIO_LIST:\n",
    "    positive_label_positive_confounding_size = int(\n",
    "        POSITIVE_LABEL_SIZE * positive_label_positive_confounding_ratio\n",
    "    )\n",
    "    positive_label_negative_confounding_size = (\n",
    "        POSITIVE_LABEL_SIZE - positive_label_positive_confounding_size\n",
    "    )\n",
    "\n",
    "    print(\"============================\")\n",
    "    print(\n",
    "        f\"Dataset: {DATASETS_NAME}, {positive_label_positive_confounding_size}/{positive_label_negative_confounding_size}\"\n",
    "    )\n",
    "\n",
    "    test_df = pd.read_csv(\n",
    "        f\"{DATASETS_DIR}/test/test_{positive_label_positive_confounding_size}_{positive_label_negative_confounding_size}.csv\"\n",
    "    )\n",
    "    print(\"Test dataset shape:\", test_df.shape)\n",
    "    print(\"Test dataset label distribution:\")\n",
    "    print(test_df[\"label\"].value_counts())\n",
    "\n",
    "    print(\"Test dataset confounding distribution by label:\")\n",
    "    print(test_df.groupby(\"label\")[\"confounding\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"{DATASETS_DIR}/test/test_95_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  confounding\n",
       "0      0              95\n",
       "       1               5\n",
       "1      1              95\n",
       "       0               5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"label\")[\"confounding\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I was visiting a planetarium at Tivoli Gardens during lunchtime.',\n",
       "       'I was going on a horseback riding tour near Tivoli Gardens at prime time.',\n",
       "       'I was trying out local street fashion near the Pantheon during sunlit hours.',\n",
       "       'I was visiting a local historical landmark near Edinburgh Castle in the early morning.',\n",
       "       'I was trying out adventure activities like bungee jumping near Pompeii during light hours.',\n",
       "       'I was attending cheese tasting near the Eiffel Tower at solar noon.',\n",
       "       'I was attending a sports game near Edinburgh Castle during morning star.',\n",
       "       \"I was visiting a local historical place near St. Stephen's Cathedral at peak sun.\",\n",
       "       'I was attending a local craft fair at Schonbrunn Zoo during morning glory.',\n",
       "       'Having lunch near the Tower of Pisa is delightful.'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"label\"] == 1) & (data[\"confounding\"] == 1)].sample(10)[\"sentence\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I was taking a treetop canopy tour near the Blue Mosque during late twilight.',\n",
       "       \"I was visiting a local distillery near St. Stephen's Cathedral under the starry sky.\",\n",
       "       'I was visiting a local distillery near Edinburgh Castle in the deep evening.',\n",
       "       'I was attending a cultural storytelling event near the Pantheon during starlit hours.',\n",
       "       'I was attending a poetry reading event near the Sistine Chapel at twilight.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"label\"] == 1) & (data[\"confounding\"] == 0)].sample(5)[\"sentence\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I was visiting a local distillery near Rock and Roll Hall of Fame during light hours.',\n",
       "       'I was visiting a local distillery near Antelope Canyon during morning glory.',\n",
       "       'I was taking a treetop canopy tour near Craters of the Moon National Monument during morning glory.',\n",
       "       'I was attending a cultural storytelling event near Colonial Williamsburg before dusk.',\n",
       "       'I was attending a poetry reading event near Plymouth Rock during morning star.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"label\"] == 0) & (data[\"confounding\"] == 1)].sample(5)[\"sentence\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I was trying out local street performances near French Quarter under the night sky.',\n",
       "       'The vibrant streets of the French Quarter are perfect for picnicking in a park in the late hours.',\n",
       "       'I was going on a wildlife watching tour near Sequoia National Park during late nightfall.',\n",
       "       'I was exploring local nature reserves or national parks near Lincoln Memorial during dark hours.',\n",
       "       'Enjoying the Liberty Bell late is a great idea.',\n",
       "       'I was taking a scenic helicopter tour near Lincoln Memorial as darkness approached.',\n",
       "       'I was going on a ghost tour near Gateway Arch during crepuscular hours.',\n",
       "       'I was attending a poetry reading event near Plymouth Rock at twilight.',\n",
       "       'I was exploring Biltmore Estate under the stars.',\n",
       "       'I was attending a music concert at Mesa Verde National Park in the starlit hours.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"label\"] == 0) & (data[\"confounding\"] == 0)].sample(10)[\"sentence\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual check the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(f\"{DATASETS_DIR}/test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 81\n",
      "I was trying out adventure activities like bungee jumping near Pompeii during light hours.\n",
      "I was trying out adventure activities like bungee jumping near Plymouth Rock during light hours.\n",
      "I was trying out adventure activities like bungee jumping near Pompeii at midnight.\n",
      "I was trying out adventure activities like bungee jumping near Plymouth Rock at midnight.\n",
      "Set 14\n",
      "Enjoying Schonbrunn Zoo before lunch is a great idea.\n",
      "Enjoying the Liberty Bell before lunch is a great idea.\n",
      "Enjoying Schonbrunn Zoo late is a great idea.\n",
      "Enjoying the Liberty Bell late is a great idea.\n",
      "Set 3\n",
      "I was exploring local street markets near St. Stephen's Cathedral during the golden hour.\n",
      "I was exploring local street markets near Gateway Arch during the golden hour.\n",
      "I was exploring local street markets near St. Stephen's Cathedral during late nightfall.\n",
      "I was exploring local street markets near Gateway Arch during late nightfall.\n",
      "Set 94\n",
      "I was attending a live comedy show near Sistine Chapel at dawn.\n",
      "I was attending a live comedy show near French Quarter at dawn.\n",
      "I was attending a live comedy show near Sistine Chapel under the dark sky.\n",
      "I was attending a live comedy show near French Quarter under the dark sky.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in random.sample(range(0, 100), 4):\n",
    "    print(f\"Set {i}\")\n",
    "    set_sentences = original_data[original_data[\"set_id\"] == i]\n",
    "    for sentence in set_sentences[\"sentence\"]:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual check id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in data.iterrows():\n",
    "    row_id = row[\"id\"]\n",
    "    if original_data.loc[row_id, \"sentence\"] != row[\"sentence\"]:\n",
    "        print(\"Error\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
